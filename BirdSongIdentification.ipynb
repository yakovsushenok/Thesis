{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BirdSongIdentification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPgfeAlZ3UwAbR2Fxpjoto",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yakovsushenok/Thesis/blob/main/BirdSongIdentification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "ibpWhcb2BuOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukG2c5mGBqfT",
        "outputId": "04dfb6e9-2412-4731-edc3-99f03d6f4639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# extracting the training data (audio files) from the zip file (12 minutes)\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/train_short_audio.zip', 'r')\n",
        "zip_ref.extractall('/content/tmp') \n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "yyqhHqKadWAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the data which has audio files that are of similar length to the testing data\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/MyDrive/train_soundscapes.zip', 'r')\n",
        "zip_ref.extractall('/content/trainSoundscapes') \n",
        "zip_ref.close()\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/train_metadata.csv\") # the metadata\n",
        "df['relative_path'] = '/content/tmp/' + df['primary_label'] + '/' + df['filename'] \n",
        "df = df[['relative_path', 'primary_label']]"
      ],
      "metadata": {
        "id": "h4DrXTGvfmQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility classes"
      ],
      "metadata": {
        "id": "CW-iaKXPK_8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "\n",
        "class AudioUtil():\n",
        "  \"\"\"\n",
        "  This class will be for various functions that I will use for the audio data\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def open(audio_file):\n",
        "    \"\"\"\n",
        "    The load method loads the audio file and produces 2 outputs:\n",
        "    - waveform (Tensor): A waveform is a graphical representation of a sound wave as it moves through a medium over time\n",
        "    - sample rate (int): In audio production, a sample rate defines how many times per second a sound is sampled. Technically speaking, it is the frequency of samples used in a digital recording.\n",
        "    The standard sample rate used for audio CDs is 44.1 kilohertz (44,100 hertz). That means each second of a song on a CD contains 44,100 individual samples.\n",
        "    \"\"\"\n",
        "    waveform, samplerate = torchaudio.load(audio_file) # https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html#loading-audio-data-into-tensor\n",
        "    return (waveform, samplerate) # right now not sure whether the \n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "q5KlKltjzAf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def numOfChannels(filename):\n",
        "\n",
        "  audioData, _ = librosa.load(filename)\n",
        "  #print(True if len(audioData.shape) == 1 else False )\n",
        "  return True if len(audioData.shape) == 1 else False \n",
        "df['numChan'] = df['relative_path'].apply(numOfChannels)\n",
        "pd.value_counts(df.numChan)"
      ],
      "metadata": {
        "id": "Xd-JqPk785Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IyB-A-6xLNlm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}