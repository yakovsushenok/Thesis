{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yakovsushenok/Thesis/blob/main/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E74CWhj4Cd-n",
        "outputId": "5f9ba6df-4ada-4dd0-f85c-a095ad2e353c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2fa2a75170>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "drive.mount('/content/gdrive')\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.matlib\n",
        "try:\n",
        "    from scipy.fftpack import fft, ifft\n",
        "except ImportError:\n",
        "    from numpy.fft import fft, ifft\n",
        "from scipy.signal import lfilter\n",
        "import scipy.io as sio\n",
        "from scipy import signal\n",
        "import gc\n",
        "import h5py\n",
        "from torchsummary import summary\n",
        "!pip install torchmetrics\n",
        "from torchmetrics import Precision, Recall, ConfusionMatrix\n",
        "from torchmetrics.functional import f1_score\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_500 = pd.read_csv(\"/content/gdrive/MyDrive/train_metadata_more_than_500.csv\")\n",
        "df_500['primary_label'] = df_500['primary_label'].apply(lambda x: x - 1)\n",
        "df_500 = df_500[['relative_path', 'primary_label']]\n",
        "df_500_toy = pd.read_csv(\"/content/gdrive/MyDrive/df_500_toy.csv\")\n",
        "toy_ind = list(df_500_toy['Unnamed: 0'])\n",
        "\n",
        "class H5DS(Dataset):\n",
        "  def __init__(self, df, path, toy_ind):\n",
        "    self.path = path\n",
        "    self.data = h5py.File(self.path, 'r')['data']\n",
        "    self.df = df\n",
        "    self.toy_ind = toy_ind\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "   \n",
        "   return (self.data[toy_ind[idx]], torch.tensor(self.df['primary_label'].iloc[idx]))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else  \"cpu\") #\n",
        "\n",
        "def inference(model, val_dl):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "  outputsList = []\n",
        "  labelsList = []\n",
        "  # Disable gradient updates\n",
        "  with torch.no_grad():\n",
        "    for data in val_dl:\n",
        "      # Get the input features and target labels, and put them on the GPU\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Normalizing\n",
        "      inputs -= inputs.min(1, keepdim=True)[0]\n",
        "      inputs /= inputs.max(1, keepdim=True)[0]\n",
        "\n",
        "      inputs = inputs[None, :, :, :]\n",
        "      inputs = inputs.permute(1, 0, 2, 3)\n",
        "      inputs = torch.cat([inputs[:, :, :round(inputs.shape[2]/3), :],inputs[:, :, round(inputs.shape[2]/3):round(inputs.shape[2]*2/3), :],inputs[:, :, round(inputs.shape[2]*2/3):, : ]], dim = 1)\n",
        "\n",
        "      # trans = inputs.detach().cpu().numpy()\n",
        "      # trans =  np.mean(trans, axis = 1)\n",
        "      # inputs =torch.from_numpy(trans).to(device)\n",
        "      # inputs = inputs[None,:,:,:]\n",
        "\n",
        "      # Get predictions\n",
        "      outputs = model(inputs.float())\n",
        "\n",
        "      # Get the predicted class with the highest score\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "      # Count of predictions that matched the target label\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "      outputsList.append(prediction.cpu().numpy())\n",
        "      labelsList.append(labels.cpu().numpy())\n",
        "  # Accuracy\n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Val Accuracy: {acc:.2f}')\n",
        "  # F1 score\n",
        "  outputs = np.concatenate(outputsList)\n",
        "  targets = np.concatenate(labelsList)\n",
        "  precision = Precision(average='micro')\n",
        "  recall = Recall(average='micro')\n",
        "  prec = precision(torch.from_numpy(outputs), torch.from_numpy(targets))\n",
        "  rec = recall(torch.from_numpy(outputs), torch.from_numpy(targets))\n",
        "  f1 = f1_score(torch.from_numpy(outputs),torch.from_numpy(targets), num_classes = 12, average='micro')\n",
        "  print(f\"F1 score: {f1}\")\n",
        "  return f1, acc, prec, rec\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QzkT_yLbhHRL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet Model\n",
        "\n",
        "[Link](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) for saving best model (how to do it)\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ],
      "metadata": {
        "id": "anhyzMFGVIMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample):\n",
        "        super().__init__()\n",
        "        if downsample:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "            self.shortcut = nn.Sequential()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.shortcut(input)\n",
        "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
        "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
        "        input = input + shortcut\n",
        "        return nn.ReLU()(input)\n",
        "\n",
        "class ResBottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels//4, kernel_size=1, stride=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels//4, out_channels//4, kernel_size=3, stride=2 if downsample else 1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(out_channels//4, out_channels, kernel_size=1, stride=1)\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if self.downsample or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2 if self.downsample else 1),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels//4)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels//4)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.shortcut(input)\n",
        "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
        "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
        "        input = nn.ReLU()(self.bn3(self.conv3(input)))\n",
        "        input = input + shortcut\n",
        "        return nn.ReLU()(input)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, in_channels, resblock, repeat, useBottleneck=False, outputs=12):\n",
        "        super().__init__()\n",
        "        self.layer0 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        if useBottleneck:\n",
        "            filters = [64, 256, 512, 1024, 2048]\n",
        "        else:\n",
        "            filters = [64, 64, 128, 256, 512]\n",
        "\n",
        "        self.layer1 = nn.Sequential()\n",
        "        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n",
        "        for i in range(1, repeat[0]):\n",
        "                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n",
        "\n",
        "        self.layer2 = nn.Sequential()\n",
        "        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n",
        "        for i in range(1, repeat[1]):\n",
        "                self.layer2.add_module('conv3_%d' % (i+1,), resblock(filters[2], filters[2], downsample=False))\n",
        "\n",
        "        self.layer3 = nn.Sequential()\n",
        "        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n",
        "        for i in range(1, repeat[2]):\n",
        "            self.layer3.add_module('conv2_%d' % (i+1,), resblock(filters[3], filters[3], downsample=False))\n",
        "\n",
        "        self.layer4 = nn.Sequential()\n",
        "        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n",
        "        for i in range(1, repeat[3]):\n",
        "            self.layer4.add_module('conv3_%d'%(i+1,), resblock(filters[4], filters[4], downsample=False))\n",
        "\n",
        "        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = torch.nn.Linear(filters[4], outputs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.layer0(input)\n",
        "        input = self.layer1(input)\n",
        "        input = self.layer2(input)\n",
        "        input = self.layer3(input)\n",
        "        input = self.layer4(input)\n",
        "        input = self.gap(input)\n",
        "        input = torch.flatten(input, start_dim=1)\n",
        "        input = self.fc(input)\n",
        "\n",
        "        return input\n",
        "class H5DS(Dataset):\n",
        "  def __init__(self, df, path):\n",
        "    self.path = path\n",
        "    self.data = h5py.File(self.path, 'r')['data']\n",
        "    self.df = df\n",
        "    self.toy_ind = toy_ind\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "   \n",
        "   return (self.data[idx], torch.tensor(self.df['primary_label'].iloc[idx]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ID1 ::: 11 Sept - 05:38; Running: ResNet18, MRCG ,(3, 256, 6025), 60 [10−5, 3], SGD, Yes, [50, 8000] --- Row 3 from ResNet18\n",
        "\n",
        "\n",
        "# reminder: time the epochs, create and save confusion matrix for test only\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else  \"cpu\") \n",
        "myModel = ResNet(3, ResBlock, [2, 2, 2, 2], useBottleneck=False, outputs=12) \n",
        "#myModel = ResNet(1, ResBlock, [2, 2, 2, 2], useBottleneck=False, outputs=12) # resnet18 # for mean MRCG only 1 channel needed, not 3 unlike for og MRCG\n",
        "myModel = myModel.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def training(model, train_dl, num_epochs, val_dl):\n",
        "  # Loss Function, Optimizer \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # For SGD\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr= 10**(-5))\n",
        "  # For Adam\n",
        "  # optimizer = torch.optim.SGD(model.parameters(), lr= 10**(-5))\n",
        "  \n",
        "  # For LR Scheduler\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3,\n",
        "                                                steps_per_epoch=int(len(train_dl)),\n",
        "                                                epochs=num_epochs,\n",
        "                                                anneal_strategy='linear')\n",
        "  \n",
        "  val_accuracy_epoch_list = [] \n",
        "  train_accuracy_epoch_list = [] \n",
        "  f1_epoch_list = []\n",
        "  val_precision_list = []\n",
        "  val_recall_list = []\n",
        "  best_f1 = 0\n",
        "  epoch_f1 = 0\n",
        "  # Epoch iterator\n",
        "  for epoch in range(num_epochs):\n",
        "    t0 = time.time()\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "    indices = []\n",
        "    # Batch iterator\n",
        "    for i, data in enumerate(train_dl):\n",
        "\n",
        "        inputs, labels = torch.tensor(data[0]).to(device), torch.tensor(data[1]).to(device) # Get the input features and target labels, and put them on the GPU\n",
        "        if torch.isnan(torch.tensor(data[0])).any() == True:\n",
        "          continue\n",
        "        \n",
        "        # Normalize the inputs\n",
        "        inputs -= inputs.min(1, keepdim=True)[0]\n",
        "        inputs /= inputs.max(1, keepdim=True)[0]\n",
        "\n",
        "        inputs = inputs[None, :, :, :]\n",
        "        inputs = inputs.permute(1, 0, 2, 3)\n",
        "        inputs = torch.cat([inputs[:, :, :round(inputs.shape[2]/3), :],inputs[:, :, round(inputs.shape[2]/3):round(inputs.shape[2]*2/3), :],inputs[:, :, round(inputs.shape[2]*2/3):, : ]], dim = 1)\n",
        "        \n",
        "        # Following code if we want mean MRCG, shape (256, 6025)\n",
        "        # trans = inputs.detach().cpu().numpy()\n",
        "        # trans =  np.mean(trans, axis = 1)\n",
        "        # inputs = torch.from_numpy(trans).to(device)\n",
        "        # inputs = inputs[None,:,:,:]\n",
        "       \n",
        "        optimizer.zero_grad() # Zero the parameter gradients\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() # Keep stats for Loss and Accuracy\n",
        "\n",
        "        _, prediction = torch.max(outputs,1) # Get the predicted class with the highest score\n",
        "        correct_prediction += (prediction == labels).sum().item() # Count of predictions that matched the target label\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "    \n",
        "    # Print stats at the end of the epoch\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    train_accuracy_epoch_list.append(acc)\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "    print(f\"TESTING:\")\n",
        "    epoch_f1, val_acc, val_prec, val_rec = inference(model, val_dl)\n",
        "    f1_epoch_list.append(epoch_f1)\n",
        "    val_accuracy_epoch_list.append(val_acc)\n",
        "    val_precision_list.append(val_prec)\n",
        "    val_recall_list.append(val_rec)\n",
        "    if epoch_f1 > best_f1 and epoch > 9:\n",
        "      torch.save(model.state_dict(), \"/content/gdrive/MyDrive/BestResnet18_ID1.pt\")\n",
        "      best_f1 = epoch_f1\n",
        "      # model = TheModelClass(*args, **kwargs)\n",
        "      # model.load_state_dict(torch.load(PATH))\n",
        "      # model.eval()\n",
        "    t1 = time.time()\n",
        "    print(f\"time for epoch: {(t1-t0)/60} minutes \")\n",
        "    torch.save(model.state_dict(), f\"/content/gdrive/MyDrive/Resnet18_ID1_Epoch{epoch}.pt\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  return train_accuracy_epoch_list, val_accuracy_epoch_list, f1_epoch_list, val_precision_list, val_recall_list\n",
        "\n",
        "\n",
        "path = '/content/gdrive/MyDrive/df_train_tensor_60_fs50-8k.h5'                \n",
        "NUM_EPOCHS = 30\n",
        "# Initializing the dataset\n",
        "myds = H5DS(df_500, path)\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items*(0.80))\n",
        "num_val = int((num_items - num_train)//2)\n",
        "num_test = num_items - num_train - num_val\n",
        "print(num_train,num_val, num_test)\n",
        "train_ds, val_ds, test_ds = random_split(myds, [num_train, num_val, num_test])\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=1, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "train_accuracy_epoch_list, val_accuracy_epoch_list, f1_epoch_list, val_precision_list, val_recall_list = training(myModel, train_dl, NUM_EPOCHS, val_dl) # Training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UbzrXt2VKTQ",
        "outputId": "32d6c169-06ca-4a60-ce07-52603cc7c3cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4800 600 600\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:178: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:179: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 3.32, Accuracy: 0.09\n",
            "TESTING:\n",
            "Val Accuracy: 0.09\n",
            "F1 score: 0.09166666865348816\n",
            "time for epoch: 14.445004232724507 minutes \n",
            "\n",
            "\n",
            "Epoch: 2, Loss: 3.11, Accuracy: 0.08\n",
            "TESTING:\n",
            "Val Accuracy: 0.09\n",
            "F1 score: 0.08500000089406967\n",
            "time for epoch: 18.59626898765564 minutes \n",
            "\n",
            "\n",
            "Epoch: 3, Loss: 3.11, Accuracy: 0.09\n",
            "TESTING:\n",
            "Val Accuracy: 0.09\n",
            "F1 score: 0.08666666597127914\n",
            "time for epoch: 19.454294820626576 minutes \n",
            "\n",
            "\n",
            "Epoch: 4, Loss: 3.11, Accuracy: 0.08\n",
            "TESTING:\n",
            "Val Accuracy: 0.09\n",
            "F1 score: 0.08500000089406967\n",
            "time for epoch: 19.44527120987574 minutes \n",
            "\n",
            "\n",
            "Epoch: 5, Loss: 3.09, Accuracy: 0.08\n",
            "TESTING:\n",
            "Val Accuracy: 0.09\n",
            "F1 score: 0.09166666865348816\n",
            "time for epoch: 19.44109236796697 minutes \n",
            "\n",
            "\n",
            "Epoch: 6, Loss: 3.12, Accuracy: 0.09\n",
            "TESTING:\n",
            "Val Accuracy: 0.09\n",
            "F1 score: 0.08500000089406967\n",
            "time for epoch: 19.448284304142 minutes \n",
            "\n",
            "\n",
            "Epoch: 7, Loss: 2.99, Accuracy: 0.13\n",
            "TESTING:\n",
            "Val Accuracy: 0.17\n",
            "F1 score: 0.16500000655651093\n",
            "time for epoch: 19.444806555906933 minutes \n",
            "\n",
            "\n",
            "Epoch: 8, Loss: 2.92, Accuracy: 0.14\n",
            "TESTING:\n",
            "Val Accuracy: 0.19\n",
            "F1 score: 0.18666665256023407\n",
            "time for epoch: 19.444874958197275 minutes \n",
            "\n",
            "\n",
            "Epoch: 9, Loss: 2.81, Accuracy: 0.17\n",
            "TESTING:\n",
            "Val Accuracy: 0.13\n",
            "F1 score: 0.1316666603088379\n",
            "time for epoch: 19.447964664300283 minutes \n",
            "\n",
            "\n",
            "Epoch: 10, Loss: 2.80, Accuracy: 0.16\n",
            "TESTING:\n",
            "Val Accuracy: 0.19\n",
            "F1 score: 0.19166666269302368\n",
            "time for epoch: 19.437802227338157 minutes \n",
            "\n",
            "\n",
            "Epoch: 11, Loss: 2.79, Accuracy: 0.18\n",
            "TESTING:\n",
            "Val Accuracy: 0.20\n",
            "F1 score: 0.2016666680574417\n",
            "time for epoch: 19.437329057852427 minutes \n",
            "\n",
            "\n",
            "Epoch: 12, Loss: 2.79, Accuracy: 0.18\n",
            "TESTING:\n",
            "Val Accuracy: 0.20\n",
            "F1 score: 0.19833332300186157\n",
            "time for epoch: 19.434319392840067 minutes \n",
            "\n",
            "\n",
            "Epoch: 13, Loss: 2.71, Accuracy: 0.19\n",
            "TESTING:\n",
            "Val Accuracy: 0.24\n",
            "F1 score: 0.23666666448116302\n",
            "time for epoch: 19.447514263788857 minutes \n",
            "\n",
            "\n",
            "Epoch: 14, Loss: 2.73, Accuracy: 0.19\n",
            "TESTING:\n",
            "Val Accuracy: 0.18\n",
            "F1 score: 0.17666666209697723\n",
            "time for epoch: 19.42776109377543 minutes \n",
            "\n",
            "\n",
            "Epoch: 15, Loss: 2.68, Accuracy: 0.20\n",
            "TESTING:\n",
            "Val Accuracy: 0.22\n",
            "F1 score: 0.21833333373069763\n",
            "time for epoch: 19.450483131408692 minutes \n",
            "\n",
            "\n",
            "Epoch: 16, Loss: 2.66, Accuracy: 0.21\n",
            "TESTING:\n",
            "Val Accuracy: 0.26\n",
            "F1 score: 0.2549999952316284\n",
            "time for epoch: 19.459357154369354 minutes \n",
            "\n",
            "\n",
            "Epoch: 17, Loss: 2.63, Accuracy: 0.23\n",
            "TESTING:\n",
            "Val Accuracy: 0.20\n",
            "F1 score: 0.19499997794628143\n",
            "time for epoch: 19.428489712874093 minutes \n",
            "\n",
            "\n",
            "Epoch: 18, Loss: 2.51, Accuracy: 0.25\n",
            "TESTING:\n",
            "Val Accuracy: 0.27\n",
            "F1 score: 0.2666666805744171\n",
            "time for epoch: 19.466051443417868 minutes \n",
            "\n",
            "\n",
            "Epoch: 19, Loss: 2.46, Accuracy: 0.26\n",
            "TESTING:\n",
            "Val Accuracy: 0.26\n",
            "F1 score: 0.2633333206176758\n",
            "time for epoch: 19.442785278956094 minutes \n",
            "\n",
            "\n",
            "Epoch: 20, Loss: 2.42, Accuracy: 0.29\n",
            "TESTING:\n",
            "Val Accuracy: 0.30\n",
            "F1 score: 0.2966666519641876\n",
            "time for epoch: 19.46652906338374 minutes \n",
            "\n",
            "\n",
            "Epoch: 21, Loss: 2.33, Accuracy: 0.30\n",
            "TESTING:\n",
            "Val Accuracy: 0.22\n",
            "F1 score: 0.22333331406116486\n",
            "time for epoch: 19.44200443426768 minutes \n",
            "\n",
            "\n",
            "Epoch: 22, Loss: 2.27, Accuracy: 0.32\n",
            "TESTING:\n",
            "Val Accuracy: 0.33\n",
            "F1 score: 0.3266666531562805\n",
            "time for epoch: 19.46478658914566 minutes \n",
            "\n",
            "\n",
            "Epoch: 23, Loss: 2.14, Accuracy: 0.34\n",
            "TESTING:\n",
            "Val Accuracy: 0.38\n",
            "F1 score: 0.38333332538604736\n",
            "time for epoch: 19.447867635885874 minutes \n",
            "\n",
            "\n",
            "Epoch: 24, Loss: 2.14, Accuracy: 0.37\n",
            "TESTING:\n",
            "Val Accuracy: 0.36\n",
            "F1 score: 0.36500000953674316\n",
            "time for epoch: 19.439618945121765 minutes \n",
            "\n",
            "\n",
            "Epoch: 25, Loss: 2.11, Accuracy: 0.37\n",
            "TESTING:\n",
            "Val Accuracy: 0.42\n",
            "F1 score: 0.4183333218097687\n",
            "time for epoch: 19.45446392695109 minutes \n",
            "\n",
            "\n",
            "Epoch: 26, Loss: 2.05, Accuracy: 0.39\n",
            "TESTING:\n",
            "Val Accuracy: 0.30\n",
            "F1 score: 0.3050000071525574\n",
            "time for epoch: 19.43508403301239 minutes \n",
            "\n",
            "\n",
            "Epoch: 27, Loss: 1.99, Accuracy: 0.42\n",
            "TESTING:\n",
            "Val Accuracy: 0.38\n",
            "F1 score: 0.3816666901111603\n",
            "time for epoch: 19.45052333275477 minutes \n",
            "\n",
            "\n",
            "Epoch: 28, Loss: 1.98, Accuracy: 0.42\n",
            "TESTING:\n",
            "Val Accuracy: 0.39\n",
            "F1 score: 0.393333375453949\n",
            "time for epoch: 19.448324879010517 minutes \n",
            "\n",
            "\n",
            "Epoch: 29, Loss: 1.89, Accuracy: 0.44\n",
            "TESTING:\n",
            "Val Accuracy: 0.46\n",
            "F1 score: 0.46000000834465027\n",
            "time for epoch: 19.464314659436543 minutes \n",
            "\n",
            "\n",
            "Epoch: 30, Loss: 1.86, Accuracy: 0.45\n",
            "TESTING:\n",
            "Val Accuracy: 0.35\n",
            "F1 score: 0.35333332419395447\n",
            "time for epoch: 19.436713377634685 minutes \n",
            "\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_acc_list) \n",
        "print(val_acc_list) "
      ],
      "metadata": {
        "id": "kDUoLoZuPJhD",
        "outputId": "f045dba4-d863-4487-d3a0-1121c20d99ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.22483850802250469, 0.4323817461971244, 0.5655344863513232, 0.6563867472390081, 0.7074390498020421, 0.7534903104813503, 0.7876640966868097, 0.8239216503438216, 0.8497603667430714, 0.8722650552198374, 0.8972702646384664, 0.9083142321316942, 0.9276932694311315, 0.9360283392373411, 0.9476974369660346, 0.9543654928110022, 0.9560325067722443, 0.9681183579912481, 0.9727026463846634, 0.972285892894353, 0.9768701812877683, 0.9812460929360284, 0.9820795999166493, 0.9818712231714941, 0.9799958324650969, 0.9818712231714941, 0.983538237132736, 0.987080641800375, 0.9856220045842884, 0.9845801208585122]\n",
            "[0.3416666666666667, 0.485, 0.5633333333333334, 0.6683333333333333, 0.6933333333333334, 0.7783333333333333, 0.7383333333333333, 0.6916666666666667, 0.7783333333333333, 0.785, 0.8183333333333334, 0.805, 0.755, 0.8066666666666666, 0.83, 0.83, 0.8016666666666666, 0.8133333333333334, 0.7933333333333333, 0.805, 0.8433333333333334, 0.8033333333333333, 0.8366666666666667, 0.825, 0.8366666666666667, 0.8366666666666667, 0.8183333333333334, 0.8266666666666667, 0.78, 0.8083333333333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [0.23395833333333332, 0.41291666666666665, 0.5372916666666666, 0.6233333333333333, 0.694375, 0.7441666666666666, 0.77625, 0.813125, 0.834375, 0.860625, 0.88125, 0.895, 0.9072916666666667, 0.9214583333333334, 0.9352083333333333, 0.9460416666666667, 0.9564583333333333, 0.9597916666666667, 0.963125, 0.9704166666666667, 0.9714583333333333, 0.9733333333333334, 0.978125, 0.9789583333333334, 0.980625, 0.9820833333333333, 0.985625, 0.9858333333333333, 0.9804166666666667, 0.9877083333333333]\n",
        "# [0.3433333333333333, 0.42833333333333334, 0.5866666666666667, 0.68, 0.67, 0.74, 0.74, 0.7733333333333333, 0.8016666666666666, 0.7733333333333333, 0.7966666666666666, 0.7866666666666666, 0.83, 0.81, 0.8466666666666667, 0.8183333333333334, 0.8266666666666667, 0.8183333333333334, 0.8483333333333334, 0.87, 0.835, 0.8116666666666666, 0.8566666666666667, 0.8583333333333333, 0.8316666666666667, 0.8483333333333334, 0.8366666666666667, 0.8116666666666666, 0.8433333333333334, 0.8216666666666667]"
      ],
      "metadata": {
        "id": "ZeUBKyrfDeX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results:\n",
        "\n",
        "---\n",
        "\n",
        "Sample Length (s) : 60\n",
        "\n",
        "lr= 10**(-5)\n",
        "\n",
        "Model: Resnet18\n",
        "\n",
        "Normalization: Yes\n",
        "\n",
        "Number of classes: 12\n",
        "\n",
        "Mini-batch size = 1\n",
        "\n",
        "Number of Samples in training: 2000*(0.8)\n",
        "\n",
        "`fs = [50, 8000]`\n",
        "\n",
        "Best Val Accurary = 0.69 epoch 14/30 $|$ 0.81 epoch 17\n",
        "\n",
        "Input shape: `(768, 6025)`\n",
        "\n",
        "\n",
        "Trainable params: 11,181,000\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Sample Length (s) : 60\n",
        "\n",
        "lr= 10**(-5)\n",
        "\n",
        "Model: Resnet 50\n",
        "\n",
        "Normalization: Yes\n",
        "\n",
        "Number of classes: 12\n",
        "\n",
        "Mini-batch size = 1\n",
        "\n",
        "Number of Samples in training: 2000*(0.8)\n",
        "\n",
        "`fs = [50, 8000]`\n",
        "\n",
        "Best Val Accurary = 0.51 epoch 11/15\n",
        "\n",
        "Input shape: `(768, 6025)`\n",
        "\n",
        "\n",
        "Trainable params: 23,559,180\n"
      ],
      "metadata": {
        "id": "rbFKIrkNS2_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "how to create confusion matrix: https://christianbernecker.medium.com/how-to-create-a-confusion-matrix-in-pytorch-38d06a7f04b7"
      ],
      "metadata": {
        "id": "bX48ey3W1XFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, val_dl):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "  outputsList = []\n",
        "  labelsList = []\n",
        "  # Disable gradient updates\n",
        "  with torch.no_grad():\n",
        "    for data in val_dl:\n",
        "      # Get the input features and target labels, and put them on the GPU\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Normalizing\n",
        "      inputs -= inputs.min(1, keepdim=True)[0]\n",
        "      inputs /= inputs.max(1, keepdim=True)[0]\n",
        "\n",
        "      inputs = inputs[None, :, :, :]\n",
        "      inputs = inputs.permute(1, 0, 2, 3)\n",
        "      inputs = torch.cat([inputs[:, :, :round(inputs.shape[2]/3), :],inputs[:, :, round(inputs.shape[2]/3):round(inputs.shape[2]*2/3), :],inputs[:, :, round(inputs.shape[2]*2/3):, : ]], dim = 1)\n",
        "\n",
        "      trans = inputs.detach().cpu().numpy()\n",
        "      trans =  np.mean(trans, axis = 1)\n",
        "      inputs =torch.from_numpy(trans).to(device)\n",
        "      inputs = inputs[None,:,:,:]\n",
        "\n",
        "      # Get predictions\n",
        "      outputs = model(inputs.float())\n",
        "\n",
        "      # Get the predicted class with the highest score\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "      # Count of predictions that matched the target label\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "      outputsList.append(prediction.cpu().numpy())\n",
        "      labelsList.append(labels.cpu().numpy())\n",
        "  # Accuracy\n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Val Accuracy: {acc:.2f}')\n",
        "  # F1 score\n",
        "  outputs = np.concatenate(outputsList)\n",
        "  targets = np.concatenate(labelsList)\n",
        "  precision = Precision(average='micro')\n",
        "  recall = Recall(average='micro')\n",
        "  prec = precision(torch.from_numpy(outputs), torch.from_numpy(targets))\n",
        "  rec = recall(torch.from_numpy(outputs), torch.from_numpy(targets))\n",
        "  f1 = f1_score(torch.from_numpy(outputs),torch.from_numpy(targets), num_classes = 12, average ='micro')\n",
        "  confmat = ConfusionMatrix(num_classes=12)\n",
        "  conf_mat = confmat(torch.from_numpy(outputs), torch.from_numpy(targets))\n",
        "  print(f\"F1 score: {f1}\")\n",
        "  torch.save(conf_mat, 'conf_mat_ID1.pt')\n",
        "  return f1, acc, prec, rec, conf_mat"
      ],
      "metadata": {
        "id": "Y7O0lBa6hfWY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet(3, ResBlock, [2, 2, 2, 2], useBottleneck=False, outputs=12) # resnet18\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else  \"cpu\") #\n",
        "model.load_state_dict(torch.load(\"/content/gdrive/MyDrive/BestResnet18_ID1.pt\"))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Mo17kG272XNG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(model, test_dl)"
      ],
      "metadata": {
        "id": "kL-eeCDV86Ja",
        "outputId": "24cfd8cc-a998-4b41-a55a-53df16c9dfdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-db59a9730e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-a6f54e9228ce>\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, val_dl)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# Get the predicted class with the highest score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1f171bda3805>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 6250] to have 3 channels, but got 1 channels instead"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOm/GlNOGOq+obwPbZ6MwAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}