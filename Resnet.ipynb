{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yakovsushenok/Thesis/blob/main/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E74CWhj4Cd-n",
        "outputId": "58e60078-253a-4144-8808-04b65715a752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.0+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd41d6dffb0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "drive.mount('/content/gdrive')\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.matlib\n",
        "try:\n",
        "    from scipy.fftpack import fft, ifft\n",
        "except ImportError:\n",
        "    from numpy.fft import fft, ifft\n",
        "from scipy.signal import lfilter\n",
        "import scipy.io as sio\n",
        "from scipy import signal\n",
        "import gc\n",
        "import h5py\n",
        "from torchsummary import summary\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.functional import f1_score\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_500 = pd.read_csv(\"/content/gdrive/MyDrive/train_metadata_more_than_500.csv\")\n",
        "df_500['primary_label'] = df_500['primary_label'].apply(lambda x: x - 1)\n",
        "df_500 = df_500[['relative_path', 'primary_label']]\n",
        "df_500_toy = pd.read_csv(\"/content/gdrive/MyDrive/df_500_toy.csv\")\n",
        "toy_ind = list(df_500_toy['Unnamed: 0'])\n",
        "\n",
        "class H5DS(Dataset):\n",
        "  def __init__(self, df, path, toy_ind):\n",
        "    self.path = path\n",
        "    self.data = h5py.File(self.path, 'r')['data']\n",
        "    self.df = df\n",
        "    self.toy_ind = toy_ind\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "   \n",
        "   return (self.data[toy_ind[idx]], torch.tensor(self.df['primary_label'].iloc[idx]))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else  \"cpu\") #\n",
        "\n",
        "def inference(model, val_dl):\n",
        "  correct_prediction = 0\n",
        "  total_prediction = 0\n",
        "  outputsList = []\n",
        "  labelsList = []\n",
        "  # Disable gradient updates\n",
        "  with torch.no_grad():\n",
        "    for data in val_dl:\n",
        "      # Get the input features and target labels, and put them on the GPU\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Normalizing\n",
        "      inputs -= inputs.min(1, keepdim=True)[0]\n",
        "      inputs /= inputs.max(1, keepdim=True)[0]\n",
        "\n",
        "      inputs = inputs[None, :, :, :]\n",
        "      inputs = inputs.permute(1, 0, 2, 3)\n",
        "      inputs = torch.cat([inputs[:, :, :round(inputs.shape[2]/3), :],inputs[:, :, round(inputs.shape[2]/3):round(inputs.shape[2]*2/3), :],inputs[:, :, round(inputs.shape[2]*2/3):, : ]], dim = 1)\n",
        "\n",
        "      # Get predictions\n",
        "      outputs = model(inputs.float())\n",
        "\n",
        "      # Get the predicted class with the highest score\n",
        "      _, prediction = torch.max(outputs,1)\n",
        "      # Count of predictions that matched the target label\n",
        "      correct_prediction += (prediction == labels).sum().item()\n",
        "      total_prediction += prediction.shape[0]\n",
        "      outputsList.append(prediction.cpu().numpy())\n",
        "      labelsList.append(labels.cpu().numpy())\n",
        "  # Accuracy\n",
        "  acc = correct_prediction/total_prediction\n",
        "  print(f'Val Accuracy: {acc:.2f}')\n",
        "  # F1 score\n",
        "  outputs = np.concatenate(outputsList)\n",
        "  targets = np.concatenate(labelsList)\n",
        "  f1 = f1_score(torch.from_numpy(outputs),torch.from_numpy(targets), num_classes = 12, average='micro')\n",
        "  print(f\"F1 score: {f1}\")\n",
        "  return f1, acc\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QzkT_yLbhHRL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet Model\n",
        "\n",
        "[Link](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) for saving best model (how to do it)\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ],
      "metadata": {
        "id": "anhyzMFGVIMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample):\n",
        "        super().__init__()\n",
        "        if downsample:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "            self.shortcut = nn.Sequential()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.shortcut(input)\n",
        "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
        "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
        "        input = input + shortcut\n",
        "        return nn.ReLU()(input)\n",
        "\n",
        "class ResBottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels//4, kernel_size=1, stride=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels//4, out_channels//4, kernel_size=3, stride=2 if downsample else 1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(out_channels//4, out_channels, kernel_size=1, stride=1)\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if self.downsample or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2 if self.downsample else 1),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels//4)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels//4)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.shortcut(input)\n",
        "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
        "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
        "        input = nn.ReLU()(self.bn3(self.conv3(input)))\n",
        "        input = input + shortcut\n",
        "        return nn.ReLU()(input)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, in_channels, resblock, repeat, useBottleneck=False, outputs=12):\n",
        "        super().__init__()\n",
        "        self.layer0 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        if useBottleneck:\n",
        "            filters = [64, 256, 512, 1024, 2048]\n",
        "        else:\n",
        "            filters = [64, 64, 128, 256, 512]\n",
        "\n",
        "        self.layer1 = nn.Sequential()\n",
        "        self.layer1.add_module('conv2_1', resblock(filters[0], filters[1], downsample=False))\n",
        "        for i in range(1, repeat[0]):\n",
        "                self.layer1.add_module('conv2_%d'%(i+1,), resblock(filters[1], filters[1], downsample=False))\n",
        "\n",
        "        self.layer2 = nn.Sequential()\n",
        "        self.layer2.add_module('conv3_1', resblock(filters[1], filters[2], downsample=True))\n",
        "        for i in range(1, repeat[1]):\n",
        "                self.layer2.add_module('conv3_%d' % (i+1,), resblock(filters[2], filters[2], downsample=False))\n",
        "\n",
        "        self.layer3 = nn.Sequential()\n",
        "        self.layer3.add_module('conv4_1', resblock(filters[2], filters[3], downsample=True))\n",
        "        for i in range(1, repeat[2]):\n",
        "            self.layer3.add_module('conv2_%d' % (i+1,), resblock(filters[3], filters[3], downsample=False))\n",
        "\n",
        "        self.layer4 = nn.Sequential()\n",
        "        self.layer4.add_module('conv5_1', resblock(filters[3], filters[4], downsample=True))\n",
        "        for i in range(1, repeat[3]):\n",
        "            self.layer4.add_module('conv3_%d'%(i+1,), resblock(filters[4], filters[4], downsample=False))\n",
        "\n",
        "        self.gap = torch.nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = torch.nn.Linear(filters[4], outputs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.layer0(input)\n",
        "        input = self.layer1(input)\n",
        "        input = self.layer2(input)\n",
        "        input = self.layer3(input)\n",
        "        input = self.layer4(input)\n",
        "        input = self.gap(input)\n",
        "        input = torch.flatten(input, start_dim=1)\n",
        "        input = self.fc(input)\n",
        "\n",
        "        return input\n",
        "class H5DS(Dataset):\n",
        "  def __init__(self, df, path):\n",
        "    self.path = path\n",
        "    self.data = h5py.File(self.path, 'r')['data']\n",
        "    self.df = df\n",
        "    self.toy_ind = toy_ind\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "   \n",
        "   return (self.data[idx], torch.tensor(self.df['primary_label'].iloc[idx]))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else  \"cpu\") #\n",
        "\n",
        "myModel = ResNet(3, ResBlock, [2, 2, 2, 2], useBottleneck=False, outputs=12) # resnet18\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else  \"cpu\") #\n",
        "myModel = myModel.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def training(model, train_dl, num_epochs, val_dl):\n",
        "  # Loss Function, Optimizer \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= 10**(-5))\n",
        "  \n",
        "  val_accuracy_epoch_list = [] \n",
        "  train_accuracy_epoch_list = [] \n",
        "  best_f1 = 0\n",
        "  epoch_f1 = 0\n",
        "  # Epoch iterator\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct_prediction = 0\n",
        "    total_prediction = 0\n",
        "    indices = []\n",
        "    # Batch iterator\n",
        "    for i, data in enumerate(train_dl):\n",
        "\n",
        "        inputs, labels = torch.tensor(data[0]).to(device), torch.tensor(data[1]).to(device) # Get the input features and target labels, and put them on the GPU\n",
        "        if torch.isnan(torch.tensor(data[0])).any() == True:\n",
        "          continue\n",
        "        \n",
        "        # Normalize the inputs\n",
        "        inputs -= inputs.min(1, keepdim=True)[0]\n",
        "        inputs /= inputs.max(1, keepdim=True)[0]\n",
        "\n",
        "        inputs = inputs[None, :, :, :]\n",
        "        inputs = inputs.permute(1, 0, 2, 3)\n",
        "        inputs = torch.cat([inputs[:, :, :round(inputs.shape[2]/3), :],inputs[:, :, round(inputs.shape[2]/3):round(inputs.shape[2]*2/3), :],inputs[:, :, round(inputs.shape[2]*2/3):, : ]], dim = 1)\n",
        "\n",
        "        optimizer.zero_grad() # Zero the parameter gradients\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() # Keep stats for Loss and Accuracy\n",
        "\n",
        "        _, prediction = torch.max(outputs,1) # Get the predicted class with the highest score\n",
        "        correct_prediction += (prediction == labels).sum().item() # Count of predictions that matched the target label\n",
        "        total_prediction += prediction.shape[0]\n",
        "\n",
        "    \n",
        "    # Print stats at the end of the epoch\n",
        "    num_batches = len(train_dl)\n",
        "    avg_loss = running_loss / num_batches\n",
        "    acc = correct_prediction/total_prediction\n",
        "    train_accuracy_epoch_list.append(acc)\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
        "    print(f\"TESTING:\")\n",
        "    epoch_f1, val_acc = inference(model, val_dl)\n",
        "    val_accuracy_epoch_list.append(val_acc)\n",
        "    if epoch_f1 > best_f1:\n",
        "      torch.save(model.state_dict(), \"/content/gdrive/MyDrive/BestResnet18.pt\")\n",
        "      best_f1 = epoch_f1\n",
        "      # model = TheModelClass(*args, **kwargs)\n",
        "      # model.load_state_dict(torch.load(PATH))\n",
        "      # model.eval()\n",
        "\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "  print('Finished Training')\n",
        "  return train_accuracy_epoch_list, val_accuracy_epoch_list\n",
        "\n",
        "\n",
        "path = '/content/gdrive/MyDrive/df_train_tensor_60_fs50-8k.h5'                \n",
        "NUM_EPOCHS = 30\n",
        "# Initializing the dataset\n",
        "myds = H5DS(df_500, path)\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items*(0.80))\n",
        "num_val = int((num_items - num_train)//2)\n",
        "num_test = num_items - num_train - num_val\n",
        "print(num_train,num_val, num_test)\n",
        "train_ds, val_ds, test_ds = random_split(myds, [num_train, num_val, num_test])\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=1, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "train_acc_list, val_acc_list = training(myModel, train_dl, NUM_EPOCHS, val_dl) # Training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UbzrXt2VKTQ",
        "outputId": "9ead976b-e2ca-47d1-94a8-1efe80a37ca4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4800 600 600\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 2.28, Accuracy: 0.23\n",
            "TESTING:\n",
            "Val Accuracy: 0.34\n",
            "F1 score: 0.34333333373069763\n",
            "\n",
            "\n",
            "Epoch: 2, Loss: 1.86, Accuracy: 0.41\n",
            "TESTING:\n",
            "Val Accuracy: 0.43\n",
            "F1 score: 0.4283333122730255\n",
            "\n",
            "\n",
            "Epoch: 3, Loss: 1.56, Accuracy: 0.54\n",
            "TESTING:\n",
            "Val Accuracy: 0.59\n",
            "F1 score: 0.5866666436195374\n",
            "\n",
            "\n",
            "Epoch: 4, Loss: 1.31, Accuracy: 0.62\n",
            "TESTING:\n",
            "Val Accuracy: 0.68\n",
            "F1 score: 0.6800000071525574\n",
            "\n",
            "\n",
            "Epoch: 5, Loss: 1.10, Accuracy: 0.69\n",
            "TESTING:\n",
            "Val Accuracy: 0.67\n",
            "F1 score: 0.6700000166893005\n",
            "\n",
            "\n",
            "Epoch: 6, Loss: 0.94, Accuracy: 0.74\n",
            "TESTING:\n",
            "Val Accuracy: 0.74\n",
            "F1 score: 0.7400000095367432\n",
            "\n",
            "\n",
            "Epoch: 7, Loss: 0.82, Accuracy: 0.78\n",
            "TESTING:\n",
            "Val Accuracy: 0.74\n",
            "F1 score: 0.7400000095367432\n",
            "\n",
            "\n",
            "Epoch: 8, Loss: 0.70, Accuracy: 0.81\n",
            "TESTING:\n",
            "Val Accuracy: 0.77\n",
            "F1 score: 0.7733333110809326\n",
            "\n",
            "\n",
            "Epoch: 9, Loss: 0.61, Accuracy: 0.83\n",
            "TESTING:\n",
            "Val Accuracy: 0.80\n",
            "F1 score: 0.8016666769981384\n",
            "\n",
            "\n",
            "Epoch: 10, Loss: 0.54, Accuracy: 0.86\n",
            "TESTING:\n",
            "Val Accuracy: 0.77\n",
            "F1 score: 0.7733333110809326\n",
            "\n",
            "\n",
            "Epoch: 11, Loss: 0.46, Accuracy: 0.88\n",
            "TESTING:\n",
            "Val Accuracy: 0.80\n",
            "F1 score: 0.7966667413711548\n",
            "\n",
            "\n",
            "Epoch: 12, Loss: 0.40, Accuracy: 0.90\n",
            "TESTING:\n",
            "Val Accuracy: 0.79\n",
            "F1 score: 0.786666750907898\n",
            "\n",
            "\n",
            "Epoch: 13, Loss: 0.35, Accuracy: 0.91\n",
            "TESTING:\n",
            "Val Accuracy: 0.83\n",
            "F1 score: 0.8299999833106995\n",
            "\n",
            "\n",
            "Epoch: 14, Loss: 0.30, Accuracy: 0.92\n",
            "TESTING:\n",
            "Val Accuracy: 0.81\n",
            "F1 score: 0.809999942779541\n",
            "\n",
            "\n",
            "Epoch: 15, Loss: 0.26, Accuracy: 0.94\n",
            "TESTING:\n",
            "Val Accuracy: 0.85\n",
            "F1 score: 0.846666693687439\n",
            "\n",
            "\n",
            "Epoch: 16, Loss: 0.22, Accuracy: 0.95\n",
            "TESTING:\n",
            "Val Accuracy: 0.82\n",
            "F1 score: 0.8183333277702332\n",
            "\n",
            "\n",
            "Epoch: 17, Loss: 0.18, Accuracy: 0.96\n",
            "TESTING:\n",
            "Val Accuracy: 0.83\n",
            "F1 score: 0.8266666531562805\n",
            "\n",
            "\n",
            "Epoch: 18, Loss: 0.17, Accuracy: 0.96\n",
            "TESTING:\n",
            "Val Accuracy: 0.82\n",
            "F1 score: 0.8183333277702332\n",
            "\n",
            "\n",
            "Epoch: 19, Loss: 0.15, Accuracy: 0.96\n",
            "TESTING:\n",
            "Val Accuracy: 0.85\n",
            "F1 score: 0.8483332991600037\n",
            "\n",
            "\n",
            "Epoch: 20, Loss: 0.12, Accuracy: 0.97\n",
            "TESTING:\n",
            "Val Accuracy: 0.87\n",
            "F1 score: 0.8700000047683716\n",
            "\n",
            "\n",
            "Epoch: 21, Loss: 0.11, Accuracy: 0.97\n",
            "TESTING:\n",
            "Val Accuracy: 0.83\n",
            "F1 score: 0.8349999785423279\n",
            "\n",
            "\n",
            "Epoch: 22, Loss: 0.10, Accuracy: 0.97\n",
            "TESTING:\n",
            "Val Accuracy: 0.81\n",
            "F1 score: 0.81166672706604\n",
            "\n",
            "\n",
            "Epoch: 23, Loss: 0.09, Accuracy: 0.98\n",
            "TESTING:\n",
            "Val Accuracy: 0.86\n",
            "F1 score: 0.856666624546051\n",
            "\n",
            "\n",
            "Epoch: 24, Loss: 0.09, Accuracy: 0.98\n",
            "TESTING:\n",
            "Val Accuracy: 0.86\n",
            "F1 score: 0.8583333492279053\n",
            "\n",
            "\n",
            "Epoch: 25, Loss: 0.08, Accuracy: 0.98\n",
            "TESTING:\n",
            "Val Accuracy: 0.83\n",
            "F1 score: 0.8316666483879089\n",
            "\n",
            "\n",
            "Epoch: 26, Loss: 0.07, Accuracy: 0.98\n",
            "TESTING:\n",
            "Val Accuracy: 0.85\n",
            "F1 score: 0.8483332991600037\n",
            "\n",
            "\n",
            "Epoch: 27, Loss: 0.06, Accuracy: 0.99\n",
            "TESTING:\n",
            "Val Accuracy: 0.84\n",
            "F1 score: 0.8366666436195374\n",
            "\n",
            "\n",
            "Epoch: 28, Loss: 0.06, Accuracy: 0.99\n",
            "TESTING:\n",
            "Val Accuracy: 0.81\n",
            "F1 score: 0.81166672706604\n",
            "\n",
            "\n",
            "Epoch: 29, Loss: 0.07, Accuracy: 0.98\n",
            "TESTING:\n",
            "Val Accuracy: 0.84\n",
            "F1 score: 0.8433333039283752\n",
            "\n",
            "\n",
            "Epoch: 30, Loss: 0.04, Accuracy: 0.99\n",
            "TESTING:\n",
            "Val Accuracy: 0.82\n",
            "F1 score: 0.8216666579246521\n",
            "\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_acc_list) \n",
        "print(val_acc_list) "
      ],
      "metadata": {
        "id": "kDUoLoZuPJhD",
        "outputId": "71a8905e-ad1a-41d5-a699-e0f4b0ee4a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23395833333333332, 0.41291666666666665, 0.5372916666666666, 0.6233333333333333, 0.694375, 0.7441666666666666, 0.77625, 0.813125, 0.834375, 0.860625, 0.88125, 0.895, 0.9072916666666667, 0.9214583333333334, 0.9352083333333333, 0.9460416666666667, 0.9564583333333333, 0.9597916666666667, 0.963125, 0.9704166666666667, 0.9714583333333333, 0.9733333333333334, 0.978125, 0.9789583333333334, 0.980625, 0.9820833333333333, 0.985625, 0.9858333333333333, 0.9804166666666667, 0.9877083333333333]\n",
            "[0.3433333333333333, 0.42833333333333334, 0.5866666666666667, 0.68, 0.67, 0.74, 0.74, 0.7733333333333333, 0.8016666666666666, 0.7733333333333333, 0.7966666666666666, 0.7866666666666666, 0.83, 0.81, 0.8466666666666667, 0.8183333333333334, 0.8266666666666667, 0.8183333333333334, 0.8483333333333334, 0.87, 0.835, 0.8116666666666666, 0.8566666666666667, 0.8583333333333333, 0.8316666666666667, 0.8483333333333334, 0.8366666666666667, 0.8116666666666666, 0.8433333333333334, 0.8216666666666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results:\n",
        "\n",
        "---\n",
        "\n",
        "Sample Length (s) : 60\n",
        "\n",
        "lr= 10**(-5)\n",
        "\n",
        "Model: Resnet18\n",
        "\n",
        "Normalization: Yes\n",
        "\n",
        "Number of classes: 12\n",
        "\n",
        "Mini-batch size = 1\n",
        "\n",
        "Number of Samples in training: 2000*(0.8)\n",
        "\n",
        "`fs = [50, 8000]`\n",
        "\n",
        "Best Val Accurary = 0.69 epoch 14/30 $|$ 0.81 epoch 17\n",
        "\n",
        "Input shape: `(768, 6025)`\n",
        "\n",
        "\n",
        "Trainable params: 11,181,000\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Sample Length (s) : 60\n",
        "\n",
        "lr= 10**(-5)\n",
        "\n",
        "Model: Resnet 50\n",
        "\n",
        "Normalization: Yes\n",
        "\n",
        "Number of classes: 12\n",
        "\n",
        "Mini-batch size = 1\n",
        "\n",
        "Number of Samples in training: 2000*(0.8)\n",
        "\n",
        "`fs = [50, 8000]`\n",
        "\n",
        "Best Val Accurary = 0.51 epoch 11/15\n",
        "\n",
        "Input shape: `(768, 6025)`\n",
        "\n",
        "\n",
        "Trainable params: 23,559,180\n"
      ],
      "metadata": {
        "id": "rbFKIrkNS2_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "how to create confusion matrix: https://christianbernecker.medium.com/how-to-create-a-confusion-matrix-in-pytorch-38d06a7f04b7"
      ],
      "metadata": {
        "id": "bX48ey3W1XFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mo17kG272XNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNT4pny9pXV/YovMpHqdu4b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}